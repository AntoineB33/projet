{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import plotly as plt\n",
    "import plotly.express as px\n",
    "from features import *\n",
    "from clustering import *\n",
    "from utils import *\n",
    "from constant import  PATH_OUTPUT, MODEL_CLUSTERING, PATH_DATA, PATH_DATA_ALL\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from images import load_images_from_folder\n",
    "\n",
    "# Example usage:\n",
    "folder_path = PATH_DATA_ALL + \"/code_test\"\n",
    "images, labels_true, folder_names = load_images_from_folder(folder_path)\n",
    "taille = len(images)\n",
    "nombre_de_canaux = 3\n",
    "# print(f\"Smallest height: {smallest_height}\")\n",
    "# print(f\"Smallest width: {smallest_width}\")\n",
    "# print(f\"Hightest height: {smallest_height2}\")\n",
    "# print(f\"Hightest width: {smallest_width2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Supposons que `images` est votre liste d'images en RGB\n",
    "descriptors_hsv = convert_color_space(images, \"HSV\") # ou \"Lab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de sift_descriptors: 42\n"
     ]
    }
   ],
   "source": [
    "# descriptors_sift = compute_sift_descriptors(images)\n",
    "sift_descriptors = extract_sift_features(descriptors_hsv)\n",
    "print(f\"Taille de sift_descriptors: {len(sift_descriptors)}\")\n",
    "# Étape 2 : Création des vecteurs de caractéristiques avec Bag of Features\n",
    "descriptors_sift = create_bag_of_features(sift_descriptors, n_clusters=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_to_use = descriptors_hsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "descriptors_hog = compute_hog_descriptors(images_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors_hist = compute_gray_histograms(images_to_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Conversion des données de clustering au format requis pour la visualisation avec Streamlit.**\n",
    "\n",
    "**TODO :**\n",
    "- Dans le fichier `utils.py`, implémenter la fonction `conversion_3d` afin de convertir un vecteur de dimension n vers une dimension 3 pour a visualisation.\n",
    "- Lien : https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42, 8192)\n",
      "(42, 256, 256, 3)\n",
      "(42, 20)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(descriptors_hog).shape)\n",
    "print(np.array(descriptors_hsv).shape)\n",
    "print(np.array(descriptors_sift).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Application de RBM et KMEANS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -4318.04, time = 3.44s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -8.70, time = 0.79s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -6.61, time = 0.65s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -5.60, time = 0.65s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -44227.75, time = 0.65s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -4.78, time = 0.99s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -4.56, time = 0.95s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -80590.83, time = 0.69s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -3.33, time = 0.67s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -4.35, time = 0.68s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -185.34, time = 0.50s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -179.08, time = 0.70s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -177.30, time = 0.82s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -176.26, time = 0.76s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -175.34, time = 0.54s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -175.35, time = 0.65s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -174.88, time = 0.59s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -174.20, time = 0.71s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -173.19, time = 0.87s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -173.93, time = 0.79s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\comma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474: ConvergenceWarning: Number of distinct clusters (9) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Métrique descripteur : HSV et HISTOGRAM\n",
      "Adjusted Mutual Information: 0.10265030070770784\n",
      "Silhouette Score: 0.9047619\n",
      "save_clustering__hist_rbm_kmeans.xlsx\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -5604.76, time = 5.86s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -5563.10, time = 4.80s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -5464.07, time = 2.64s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -5458.39, time = 2.94s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -5418.81, time = 2.27s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -5401.26, time = 2.51s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -5356.28, time = 2.32s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -5265.82, time = 2.90s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -5214.11, time = 2.77s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -5295.01, time = 2.05s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -89.84, time = 0.15s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -78.41, time = 0.61s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -54.59, time = 0.42s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -44.04, time = 0.20s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -42.41, time = 0.24s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -36.10, time = 0.29s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -36.94, time = 0.18s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -46.84, time = 0.21s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -17.54, time = 0.17s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -36.78, time = 0.32s\n",
      "########## Métrique descripteur : HSV et HISTOGRAM\n",
      "Adjusted Mutual Information: 0.05908953742384915\n",
      "Silhouette Score: 0.112003215\n",
      "save_clustering__hog_rbm_kmeans.xlsx\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -93.37, time = 0.01s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -130.94, time = 0.01s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -0.00, time = 0.06s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -201.82, time = 0.01s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -813.23, time = 0.01s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -1429.04, time = 0.01s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -527.45, time = 0.01s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = 0.00, time = 0.07s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = 0.00, time = 0.01s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = 0.00, time = 0.01s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -184.68, time = 0.39s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -179.42, time = 0.38s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -176.93, time = 0.38s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -175.34, time = 0.77s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -174.14, time = 0.61s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -173.03, time = 0.24s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -171.58, time = 0.54s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -171.67, time = 0.13s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -171.81, time = 0.19s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -169.86, time = 0.22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\comma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Métrique descripteur : HSV et HISTOGRAM\n",
      "Adjusted Mutual Information: 0.14812854818154125\n",
      "Silhouette Score: 0.9047619\n",
      "save_clustering__sift_rbm_kmeans.xlsx\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -11.97, time = 0.49s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -6.64, time = 0.48s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -4.07, time = 0.69s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -2.83, time = 0.58s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -2.21, time = 0.51s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -1.71, time = 0.56s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -730081.05, time = 0.42s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -1.34, time = 0.52s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -1.15, time = 0.58s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -1.07, time = 0.47s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -184.67, time = 0.24s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -180.12, time = 0.51s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -177.68, time = 0.37s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -173.69, time = 0.35s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -171.73, time = 0.59s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -171.50, time = 0.66s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -169.26, time = 0.43s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -166.28, time = 0.54s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -166.08, time = 0.34s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -166.52, time = 0.68s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\comma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Métrique descripteur : HSV et HISTOGRAM\n",
      "Adjusted Mutual Information: 0.14812854818154125\n",
      "Silhouette Score: 0.9047619\n",
      "save_clustering_HSV_hist_rbm_kmeans.xlsx\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -5631.89, time = 8.09s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -5584.06, time = 10.32s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -5526.12, time = 11.11s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -5496.78, time = 10.16s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -5456.93, time = 9.72s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -5429.12, time = 7.09s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -5411.58, time = 1.33s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -5319.39, time = 6.13s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -5303.60, time = 15.81s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -5283.76, time = 2.61s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -89.17, time = 0.05s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -62.38, time = 0.28s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -51.42, time = 0.11s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -35.86, time = 0.27s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -28.82, time = 0.26s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -32.91, time = 0.10s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -22.24, time = 0.07s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -17.08, time = 0.05s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -12.03, time = 0.05s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -14.25, time = 0.05s\n",
      "########## Métrique descripteur : HSV et HISTOGRAM\n",
      "Adjusted Mutual Information: 0.004413817189262938\n",
      "Silhouette Score: 0.07514211\n",
      "save_clustering_HSV_hog_rbm_kmeans.xlsx\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -0.00, time = 0.01s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -397.33, time = 0.01s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -604.76, time = 0.05s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = 0.00, time = 0.01s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = 0.00, time = 0.01s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = 0.00, time = 0.00s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = 0.00, time = 0.01s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = 0.00, time = 0.07s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = 0.00, time = 0.01s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = 0.00, time = 0.01s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -184.67, time = 0.28s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -179.38, time = 0.21s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -177.01, time = 0.14s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -175.52, time = 0.11s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -173.72, time = 0.12s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -173.40, time = 0.13s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -172.48, time = 0.24s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -171.86, time = 0.23s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -171.50, time = 0.27s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -170.82, time = 0.50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\comma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474: ConvergenceWarning: Number of distinct clusters (9) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Métrique descripteur : HSV et HISTOGRAM\n",
      "Adjusted Mutual Information: 0.12455613933161724\n",
      "Silhouette Score: 0.88095236\n",
      "save_clustering_HSV_sift_rbm_kmeans.xlsx\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "images_to_use = [images, convert_color_space(images, \"HSV\")]\n",
    "descs0 = [\"\", \"HSV\"]\n",
    "descs = [\"hist\", \"hog\", \"sift\"]\n",
    "list_dict=[]\n",
    "\n",
    "for d0 in range(len(descs0)):\n",
    "    descriptors_hog = compute_hog_descriptors(images_to_use[d0])\n",
    "    descriptors_hist = compute_gray_histograms(images_to_use[d0])\n",
    "    sift_descriptors = extract_sift_features(images_to_use[d0])\n",
    "    descriptors_sift = create_bag_of_features(sift_descriptors, n_clusters=20)\n",
    "    descriptors = [descriptors_hist, descriptors_hog, descriptors_sift]\n",
    "    for d in range(len(descs)):\n",
    "\n",
    "        # Présumons que `images` est votre liste d'images prétraitées et aplatie en vecteurs\n",
    "\n",
    "        # Initialisation de la classe StackedRBM\n",
    "        stacked_rbm = StackedRBM(n_components_list=[256, 128], n_iter=10, learning_rate=0.01, batch_size=10)\n",
    "\n",
    "        # Ajustement des RBMs sur les données d'image\n",
    "        stacked_rbm.fit(descriptors[d])\n",
    "\n",
    "        # Transformation des images en nouvelles représentations avec les RBMs entraînés\n",
    "        transformed_images = stacked_rbm.transform(descriptors[d])\n",
    "\n",
    "        # Normalisation des caractéristiques pour améliorer les performances de K-Means\n",
    "        scaler = StandardScaler()\n",
    "        transformed_images_scaled = conversion_3d(transformed_images)\n",
    "\n",
    "        # Clustering avec K-Means\n",
    "        kmeans = KMeans(n_clusters=20, random_state=42)\n",
    "        clusters = kmeans.fit_predict(transformed_images_scaled)\n",
    "        \n",
    "        \n",
    "        metric = show_metric(labels_true, clusters, transformed_images_scaled, bool_show=True, name_descriptor=\"HSV et HISTOGRAM\", name_model = \"Stacked RBM\", bool_return=True)\n",
    "        list_dict.append(metric)\n",
    "        \n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        descriptors_norm = scaler.fit_transform(descriptors[d])\n",
    "        \n",
    "        x_3d_norm = conversion_3d(descriptors_norm)\n",
    "        \n",
    "        df = create_df_to_export(x_3d_norm, labels_true, kmeans.labels_)\n",
    "\n",
    "        # sauvegarde des données\n",
    "        df.to_excel(PATH_OUTPUT+f\"/save_clustering_{descs0[d0]}_{descs[d]}_rbm_kmeans.xlsx\")\n",
    "        print(f\"save_clustering_{descs0[d0]}_{descs[d]}_rbm_kmeans.xlsx\")\n",
    "        \n",
    "df_metric = pd.DataFrame(list_dict)\n",
    "df_metric.to_excel(PATH_OUTPUT+\"/save_metric.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "##### Résultat ######\n",
      "########## Métrique descripteur : HSV_HISTOGRAM\n",
      "Adjusted Mutual Information: -0.00973927291987954\n",
      "Silhouette Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n##### Résultat ######\")\n",
    "# metric_hist = show_metric(labels_true, clusters, transformed_images_scaled, bool_show=True, name_descriptor=\"HISTOGRAM\", bool_return=True)\n",
    "\n",
    "metric_hsv_hist_rbm = show_metric(labels_true, clusters, transformed_images_scaled, bool_show=True, name_descriptor=\"HSV et HISTOGRAM\", name_model = \"Stacked RBM\", bool_return=True)\n",
    "# metric_hsv_hog_rbm = pd.read_excel(\"output/save_clustering_hsv_hog_rbm_kmeans.xlsx\")\n",
    "# metric_hsv_sift_rbm = pd.read_excel(\"output/save_clustering_hsv_sift_rbm_kmeans.xlsx\")\n",
    "# metric_hist_rbm = pd.read_excel(\"output/save_clustering_hist_rbm_kmeans.xlsx\")\n",
    "# metric_hog_rbm = pd.read_excel(\"output/save_clustering_hog_rbm_kmeans.xlsx\")\n",
    "# metric_sift_rbm = pd.read_excel(\"output/save_clustering_sift_rbm_kmeans.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Conversion des données de clustering au format requis pour la visualisation avec Streamlit.**\n",
    "\n",
    "**TODO :**\n",
    "- Dans le fichier `utils.py`, implémenter la fonction `conversion_3d` afin de convertir un vecteur de dimension n vers une dimension 3 pour a visualisation.\n",
    "- Lien : https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "descriptors_hsv_hist_rbm_norm = scaler.fit_transform(descriptors_hsv_hist_rbm)\n",
    "descriptors_hsv_hog_rbm_norm = scaler.fit_transform(descriptors_hsv_hog_rbm)\n",
    "descriptors_hsv_sift_rbm_norm = scaler.fit_transform(descriptors_hsv_sift_rbm)\n",
    "descriptors_hsv_rbm_norm = scaler.fit_transform(descriptors_hsv_rbm)\n",
    "descriptors_hist_rbm_norm = scaler.fit_transform(descriptors_hist_rbm)\n",
    "descriptors_hog_rbm_norm = scaler.fit_transform(descriptors_hog_rbm)\n",
    "descriptors_sift_rbm_norm = scaler.fit_transform(descriptors_sift_rbm)\n",
    "descriptors_rbm_norm = scaler.fit_transform(descriptors_rbm)\n",
    "\n",
    "#conversion vers un format 3D pour la visualisation\n",
    "# x_3d_hist = conversion_3d(descriptors_hist_norm)\n",
    "# # x_3d_hog = conversion_3d(descriptors_hog_norm)\n",
    "\n",
    "x_3d_hsv_hist_rbm_norm = conversion_3d(descriptors_hsv_hist_rbm_norm)\n",
    "x_3d_hsv_hog_rbm_norm = conversion_3d(descriptors_hsv_hog_rbm_norm)\n",
    "x_3d_hsv_sift_rbm_norm = conversion_3d(descriptors_hsv_sift_rbm_norm)\n",
    "x_3d_hsv_rbm_norm = conversion_3d(descriptors_hsv_rbm_norm)\n",
    "x_3d_hist_rbm_norm = conversion_3d(descriptors_hist_rbm_norm)\n",
    "x_3d_hog_rbm_norm = conversion_3d(descriptors_hog_rbm_norm)\n",
    "x_3d_sift_rbm_norm = conversion_3d(descriptors_sift_rbm_norm)\n",
    "x_3d_rbm_norm = conversion_3d(descriptors_rbm_norm)\n",
    "\n",
    "# création des dataframe pour la sauvegarde des données pour la visualisation\n",
    "df_hist = create_df_to_export(x_3d_hist, labels_true, kmeans.labels_)\n",
    "# df_hog = create_df_to_export(x_3d_hog, labels_true, kmeans.labels_)\n",
    "\n",
    "df_hsv_hist_rbm = create_df_to_export(x_3d_hsv_hist_rbm_norm, labels_true, kmeans.labels_)\n",
    "df_hsv_hog_rbm = create_df_to_export(x_3d_hsv_hog_rbm_norm, labels_true, kmeans.labels_)\n",
    "df_hsv_sift_rbm = create_df_to_export(x_3d_hsv_sift_rbm_norm, labels_true, kmeans.labels_)\n",
    "df_hsv_rbm = create_df_to_export(x_3d_hsv_rbm_norm, labels_true, kmeans.labels_)\n",
    "df_hist_rbm = create_df_to_export(x_3d_hist_rbm_norm, labels_true, kmeans.labels_)\n",
    "df_hist_rbm = create_df_to_export(x_3d_hist_rbm_norm, labels_true, kmeans.labels_)\n",
    "df_hog_rbm = create_df_to_export(x_3d_hog_rbm_norm, labels_true, kmeans.labels_)\n",
    "df_sift_rbm = create_df_to_export(x_3d_sift_rbm_norm, labels_true, kmeans.labels_)\n",
    "df_3d_rbm = create_df_to_export(x_3d_rbm_norm, labels_true, kmeans.labels_)\n",
    "\n",
    "\n",
    "# Vérifie si le dossier existe déjà\n",
    "if not os.path.exists(PATH_OUTPUT):\n",
    "    # Crée le dossier\n",
    "    os.makedirs(PATH_OUTPUT)\n",
    "\n",
    "# sauvegarde des données\n",
    "df_hist.to_excel(PATH_OUTPUT+\"/save_clustering_hsv_hist_rbm_kmeans.xlsx\")\n",
    "# df_hog.to_excel(PATH_OUTPUT+\"/save_clustering_hog_kmeans.xlsx\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1554332066.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[14], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    df_metric = pd.DataFrame(list_dict)df_metric.to_excel(PATH_OUTPUT+\"/save_metric.xlsx\")\u001b[0m\n\u001b[1;37m                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "list_dict = [metric_hsv_hist_rbm, metric_hsv_hog_rbm, metric_hsv_sift_rbm, metric_hsv_rbm, metric_hist_rbm, metric_hog_rbm, metric_sift_rbm, metric_rbm]\n",
    "df_metric = pd.DataFrame(list_dict)\n",
    "df_metric.to_excel(PATH_OUTPUT+\"/save_metric.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
